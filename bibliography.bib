@misc{borkman2021unityperceptiongeneratesynthetic,
      title={Unity Perception: Generate Synthetic Data for Computer Vision}, 
      author={Steve Borkman and Adam Crespi and Saurav Dhakad and Sujoy Ganguly and Jonathan Hogins and You-Cyuan Jhang and Mohsen Kamalzadeh and Bowen Li and Steven Leal and Pete Parisi and Cesar Romero and Wesley Smith and Alex Thaman and Samuel Warren and Nupur Yadav},
      year={2021},
      eprint={2107.04259},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2107.04259}, 
}

@misc{UnityAssetStore,
  title        = {Unity Asset Store - the Best Assets for Game Making},
  author       = {Unity Technologies},
  howpublished = {\url{https://assetstore.unity.com/}},
  year         = {2024}
}

@misc{unity-perception2022,
    title={Unity {P}erception Package},
    author={{Unity Technologies}},
    howpublished={\url{https://github.com/Unity-Technologies/com.unity.perception}},
    year={2020}
}

@manual{sun_angle_randomizer,
  title = {Unity Perception Package: SunAngleRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.SunAngleRandomizer.html},
  note = {Accessed: 2024-11-13}
}
@manual{rotation_randomizer,
  title = {Unity Perception Package: RotationRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.RotationRandomizer.html},
  note = {Accessed: 2024-11-13}
}
@misc{secrets_of_apagayo_island_video,
  author       = {The Secrets of Apagayo Island},
  title        = {Unity Tutorial: Creating Randomized Synthetic Images with Unity3d Perception},
  year         = {2023},
  url          = {https://www.youtube.com/watch?v=AkuOpnWIa6s},
  note         = {Accessed: 2024-11-13}
}

@manual{color_randomizer,
  title = {Unity Perception Package: ColorRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.ColorRandomizer.html},
  note = {Accessed: 2024-11-13}
}

@InProceedings{10.1007/978-3-642-15549-9_55,
author="Fergus, Rob
and Bernal, Hector
and Weiss, Yair
and Torralba, Antonio",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="Semantic Label Sharing for Learning with Many Categories",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="762--775",
abstract="In an object recognition scenario with tens of thousands of categories, even a small number of labels per category leads to a very large number of total labels required. We propose a simple method of label sharing between semantically similar categories. We leverage the WordNet hierarchy to define semantic distance between any two categories and use this semantic distance to share labels. Our approach can be used with any classifier. Experimental results on a range of datasets, upto 80 million images and 75,000 categories in size, show that despite the simplicity of the approach, it leads to significant improvements in performance.",
isbn="978-3-642-15549-9"
}

@misc{wolfram_spherical_coordinates,
  title = {Spherical Coordinates},
  author = {Weisstein, Eric W.},
  year = {2024},
  url = {https://mathworld.wolfram.com/SphericalCoordinates.html}
}
@misc{unity_quaternion_lookrotation,
  title = {Quaternion.LookRotation},
  author = {Unity Technologies},
  year = {2024},
  url = {https://docs.unity3d.com/ScriptReference/Quaternion.LookRotation.html},
  note = {Accessed: 2024-11-18}
}
@misc{cgtrader,
  title = {CGTrader - 3D Models for Professionals},
    author = {{CGTrader}},
  howpublished = {\url{https://www.cgtrader.com/}},
  note = {Accessed: 2024-11-19}
}
@misc{sketchfab,
  author = {{Sketchfab}},
  title = {Sketchfab - The best 3D viewer on the web},
  howpublished = {\url{https://sketchfab.com/about}},
  note = {Accessed: 2024-11-19}
}

@misc{dnv_wiki,
  author = {{DNV}},
  title = {Azure DevOps Community for ReVolt.},
  howpublished = {Internal resource},
  note = {Accessed: 2024-11-19. Restricted}
}


@Article{jimaging8110310,
AUTHOR = {Man, Keith and Chahl, Javaan},
TITLE = {A Review of Synthetic Image Data and Its Use in Computer Vision},
JOURNAL = {Journal of Imaging},
VOLUME = {8},
YEAR = {2022},
NUMBER = {11},
ARTICLE-NUMBER = {310},
URL = {https://www.mdpi.com/2313-433X/8/11/310},
PubMedID = {36422059},
ISSN = {2313-433X},
ABSTRACT = {Development of computer vision algorithms using convolutional neural networks and deep learning has necessitated ever greater amounts of annotated and labelled data to produce high performance models. Large, public data sets have been instrumental in pushing forward computer vision by providing the data necessary for training. However, many computer vision applications cannot rely on general image data provided in the available public datasets to train models, instead requiring labelled image data that is not readily available in the public domain on a large scale. At the same time, acquiring such data from the real world can be difficult, costly to obtain, and manual labour intensive to label in large quantities. Because of this, synthetic image data has been pushed to the forefront as a potentially faster and cheaper alternative to collecting and annotating real data. This review provides general overview of types of synthetic image data, as categorised by synthesised output, common methods of synthesising different types of image data, existing applications and logical extensions, performance of synthetic image data in different applications and the associated difficulties in assessing data performance, and areas for further research.},
DOI = {10.3390/jimaging8110310}
}



@article{10.1145/3042064,
author = {Ioannidou, Anastasia and Chatzilari, Elisavet and Nikolopoulos, Spiros and Kompatsiaris, Ioannis},
title = {Deep Learning Advances in Computer Vision with 3D Data: A Survey},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3042064},
doi = {10.1145/3042064},
abstract = {Deep learning has recently gained popularity achieving state-of-the-art performance in tasks involving text, sound, or image processing. Due to its outstanding performance, there have been efforts to apply it in more challenging scenarios, for example, 3D data processing. This article surveys methods applying deep learning on 3D data and provides a classification based on how they exploit them. From the results of the examined works, we conclude that systems employing 2D views of 3D data typically surpass voxel-based (3D) deep models, which however, can perform better with more layers and severe data augmentation. Therefore, larger-scale datasets and increased resolutions are required.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {20},
numpages = {38},
keywords = {3D data, 3D object recognition, 3D object retrieval, 3D segmentation, convolutional neural networks, deep learning}
}

@book{nikolenko2021synthetic,
  title={Synthetic data for deep learning},
  author={Nikolenko, Sergey I},
  volume={174},
  year={2021},
  publisher={Springer}
}
@misc{rajpura2017objectdetectionusingdeep,
      title={Object Detection Using Deep CNNs Trained on Synthetic Images}, 
      author={Param S. Rajpura and Hristo Bojinov and Ravi S. Hegde},
      year={2017},
      eprint={1706.06782},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1706.06782}, 
}

@article{Ying_2019,
doi = {10.1088/1742-6596/1168/2/022022},
url = {https://dx.doi.org/10.1088/1742-6596/1168/2/022022},
year = {2019},
month = {feb},
publisher = {IOP Publishing},
volume = {1168},
number = {2},
pages = {022022},
author = {Xue Ying},
title = {An Overview of Overfitting and its Solutions},
journal = {Journal of Physics: Conference Series},
abstract = {Overfitting is a fundamental issue in supervised machine learning which prevents us from perfectly generalizing the models to well fit observed data on training data, as well as unseen data on testing set. Because of the presence of noise, the limited size of training set, and the complexity of classifiers, overfitting happens. This paper is going to talk about overfitting from the perspectives of causes and solutions. To reduce the effects of overfitting, various strategies are proposed to address to these causes: 1) “early-stopping” strategy is introduced to prevent overfitting by stopping training before the performance stops optimize; 2) “network-reduction” strategy is used to exclude the noises in training set; 3) “data-expansion” strategy is proposed for complicated models to fine-tune the hyper-parameters sets with a great amount of data; and 4) “regularization” strategy is proposed to guarantee models performance to a great extent while dealing with real world issues by feature-selection, and by distinguishing more useful and less useful features.}
}

@article{Labelling,
author = {Christoph Sager, Christian Janiesch and Patrick Zschech},
title = {A survey of image labelling for computer vision applications},
journal = {Journal of Business Analytics},
volume = {4},
number = {2},
pages = {91--110},
year = {2021},
publisher = {Taylor \& Francis},
doi = {10.1080/2573234X.2021.1908861},


URL = { 
    
        https://doi.org/10.1080/2573234X.2021.1908861
    
    

},
eprint = { 
    
        https://doi.org/10.1080/2573234X.2021.1908861
    
    

}

}

@Article{labelingMethods,
AUTHOR = {Mohammed, Sarfaraz Ahmed and Ralescu, Anca L.},
TITLE = {Insights into Image Understanding: Segmentation Methods for Object Recognition and Scene Classification},
JOURNAL = {Algorithms},
VOLUME = {17},
YEAR = {2024},
NUMBER = {5},
ARTICLE-NUMBER = {189},
URL = {https://www.mdpi.com/1999-4893/17/5/189},
ISSN = {1999-4893},
ABSTRACT = {Image understanding plays a pivotal role in various computer vision tasks, such as extraction of essential features from images, object detection, and segmentation. At a higher level of granularity, both semantic and instance segmentation are necessary for fully grasping a scene. In recent times, the concept of panoptic segmentation has emerged as a field of study that unifies semantic and instance segmentation. This article sheds light on the pivotal role of panoptic segmentation as a visualization tool for understanding scene components, including object detection, categorization, and precise localization of scene elements. Advancements in achieving panoptic segmentation and suggested improvements to the predicted outputs through a top-down approach are discussed. Furthermore, datasets relevant to both scene recognition and panoptic segmentation are explored to facilitate a comparative analysis. Finally, the article outlines certain promising directions in image recognition and analysis by underlining the ongoing evolution in image understanding methodologies.},
DOI = {10.3390/a17050189}
}



@article{waterrendering,
  title={Using vertex texture displacement for realistic water rendering},
  author={Kryachko, Yuri},
  journal={GPU gems},
  volume={2},
  pages={283--294},
  year={2005}
}

@article{gan,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative adversarial networks},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3422622},
doi = {10.1145/3422622},
abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
journal = {Commun. ACM},
month = oct,
pages = {139–144},
numpages = {6}
}

@misc{hallucination,
      title={Generative AI for Synthetic Data Generation: Methods, Challenges and the Future}, 
      author={Xu Guo and Yiqiang Chen},
      year={2024},
      eprint={2403.04190},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.04190}, 
}

@manual{UMLdiagram,
  title        = {Randomization in Unity Perception},
  author       = {Unity Technologies},
  year         = {2024},
  url          = {https://docs.unity3d.com/Packages/com.unity.perception@1.0/manual/Randomization/index.html},
  note         = {Accessed: 2024-12-06}
}

@misc{Dezgo2024,
  author       = {Dezgo},
  title        = {Image to Image AI Generator - Dezgo},
  year         = {2024},
  url          = {https://dezgo.com/image2image},
  note         = {Accessed: 2024-12-07}
}

@inproceedings{aiToExoand,
 author = {Zhang, Yifan and Zhou, Daquan and Hooi, Bryan and Wang, Kai and Feng, Jiashi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {76558--76618},
 publisher = {Curran Associates, Inc.},
 title = {Expanding Small-Scale Datasets with Guided Imagination},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/f188a55392d3a7509b0b27f8d24364bb-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@mastersthesis{NTNUFerry,
  author       = {Kjønås, Ingunn},
  title        = {Maritime Object Detection in LWIR-images using Deep Learning methods with Data Augmentation},
  school       = {Norwegian University of Science and Technology (NTNU)},
  year         = {2021},
  address      = {Trondheim, Norway},
  url          = {https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2789448},
  note         = {Master's thesis},
}

@misc{SingaporeMaritimeDataset,
  author       = {Prasad, Dilip K.},
  title        = {Singapore Maritime Dataset},
  year         = {n.d.},
  howpublished = {\url{https://sites.google.com/site/dilipprasad/home/singapore-maritime-dataset?authuser=0}},
  note         = {Accessed: 2024-12-07},
}


@article{hinter,
  author       = {Stefan Hinterstoisser and
                  Olivier Pauly and
                  Hauke Heibel and
                  Martina Marek and
                  Martin Bokeloh},
  title        = {An Annotation Saved is an Annotation Earned: Using Fully Synthetic
                  Training for Object Instance Detection},
  journal      = {CoRR},
  volume       = {abs/1902.09967},
  year         = {2019},
  url          = {http://arxiv.org/abs/1902.09967},
  eprinttype    = {arXiv},
  eprint       = {1902.09967},
  timestamp    = {Tue, 21 May 2019 18:03:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1902-09967.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{wood,
  author={Wood, Erroll and Baltruaitis, Tadas and Zhang, Xucong and Sugano, Yusuke and Robinson, Peter and Bulling, Andreas},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Rendering of Eyes for Eye-Shape Registration and Gaze Estimation}, 
  year={2015},
  volume={},
  number={},
  pages={3756-3764},
  keywords={Shape;Estimation;Training data;Head;Geometry;Three-dimensional displays;Computational modeling},
  doi={10.1109/ICCV.2015.428}}

@INPROCEEDINGS{r-cnn,
  author={Johnson-Roberson, Matthew and Barto, Charles and Mehta, Rounak and Sridhar, Sharath Nittur and Rosaen, Karl and Vasudevan, Ram},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?}, 
  year={2017},
  volume={},
  number={},
  pages={746-753},
  keywords={Engines;Training;Machine learning;Data models;Robots;Training data;Automobiles;deep learning;simulation;object detection;autonomous driving},
  doi={10.1109/ICRA.2017.7989092}}

@misc{unity_standard_assets_installation,
  author       = {Unity Technologies},
  title        = {Standard Assets},
  year         = {2016},
  url          = {https://docs.unity3d.com/540/Documentation/Manual/HOWTO-InstallStandardAssets.html},
  note         = {Accessed: 2024-12-10}
}

@misc{unity_rain_maker,
  author       = {Jeff Johnson},
  title        = {Rain Maker: 2D and 3D Rain Particle System for Unity},
  year         = {2022},
  url          = {https://assetstore.unity.com/packages/vfx/particles/environment/rain-maker-2d-and-3d-rain-particle-system-for-unity-34938#description},
  note         = {Accessed: 2024-12-10}
}

@article{safety,
title = {Deep learning for autonomous ship-oriented small ship detection},
journal = {Safety Science},
volume = {130},
pages = {104812},
year = {2020},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2020.104812},
url = {https://www.sciencedirect.com/science/article/pii/S0925753520302095},
author = {Zhijun Chen and Depeng Chen and Yishi Zhang and Xiaozhao Cheng and Mingyang Zhang and Chaozhong Wu},
keywords = {Autonomous ship, Small ship detection, Wasserstein generative adversarial network, Convolutional neural network, Ship safety},
abstract = {Small ship detection is an important topic in autonomous ship technology and plays an essential role in shipping safety. Since traditional object detection techniques based on the shipborne radar are not qualified for the task of near and small ship detection, deep learning-based image recognition methods based on video surveillance systems can be naturally utilized on autonomous vessels to effectively detect near and small ships. However, a limited number of real-world samples of small ships may fail to train a learning method that can accurately detect small ships in most cases. To address this, a novel hybrid deep learning method that combines a modified Generative Adversarial Network (GAN) and a Convolutional Neural Network (CNN)-based detection approach is proposed for small ship detection. Specifically, a Gaussian Mixture Wasserstein GAN with Gradient Penalty is utilized to first directly generate sufficient informative artificial samples of small ships based on the zero-sum game between a generator and a discriminator, and then an improved CNN-based real-time detection method is trained on both the original and the generated data for accurate small ship detection. Experimental results show that the proposed deep learning method (a) is competent to generate sufficient informative small ship samples and (b) can obtain significantly improved and robust results of small ship detection. The results also indicate that the proposed method can be effectively applied to ensuring autonomous ship safety.}
}

@misc{OpenAIChatGPT2024,
  author       = {OpenAI},
  title        = {ChatGPT: GPT-4.5},
  year         = {2024},
  howpublished = {\url{https://chat.openai.com}},
  note         = {An AI language model used for generating and discussing textual and technical content. Accessed on [insert date of access].}
}

@misc{GoogleNotebookLM2024,
  author       = {Google},
  title        = {NotebookLM},
  year         = {2024},
  howpublished = {\url{https://notebooklm.google/}},
  note         = {An AI-powered tool for summarizing, exploring, and interacting with notes and documents. Accessed on [insert date of access].}
}

@misc{GitHubCopilot2024,
  author       = {GitHub},
  title        = {GitHub Copilot},
  year         = {2024},
  howpublished = {\url{https://github.com/features/copilot}},
  note         = {An AI-powered code completion tool developed by GitHub. Accessed on [insert date of access].}
}