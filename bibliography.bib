@misc{borkman2021unityperceptiongeneratesynthetic,
      title={Unity Perception: Generate Synthetic Data for Computer Vision}, 
      author={Steve Borkman and Adam Crespi and Saurav Dhakad and Sujoy Ganguly and Jonathan Hogins and You-Cyuan Jhang and Mohsen Kamalzadeh and Bowen Li and Steven Leal and Pete Parisi and Cesar Romero and Wesley Smith and Alex Thaman and Samuel Warren and Nupur Yadav},
      year={2021},
      eprint={2107.04259},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2107.04259}, 
}

@misc{UnityAssetStore,
  title        = {Unity Asset Store - the Best Assets for Game Making},
  author       = {Unity Technologies},
  howpublished = {\url{https://assetstore.unity.com/}},
  year         = {2024}
}

@misc{unity-perception2022,
    title={Unity {P}erception Package},
    author={{Unity Technologies}},
    howpublished={\url{https://github.com/Unity-Technologies/com.unity.perception}},
    year={2020}
}

@manual{sun_angle_randomizer,
  title = {Unity Perception Package: SunAngleRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.SunAngleRandomizer.html},
  note = {Accessed: 2024-11-13}
}
@manual{rotation_randomizer,
  title = {Unity Perception Package: RotationRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.RotationRandomizer.html},
  note = {Accessed: 2024-11-13}
}
@misc{secrets_of_apagayo_island_video,
  author       = {The Secrets of Apagayo Island},
  title        = {Unity Tutorial: Creating Randomized Synthetic Images with Unity3d Perception},
  year         = {2023},
  url          = {https://www.youtube.com/watch?v=AkuOpnWIa6s},
  note         = {Accessed: 2024-11-13}
}

@manual{color_randomizer,
  title = {Unity Perception Package: ColorRandomizer API},
  author = {{Unity Technologies}},
  year = {2023},
  url = {https://docs.unity3d.com/Packages/com.unity.perception@0.5/api/UnityEngine.Experimental.Perception.Randomization.Randomizers.SampleRandomizers.ColorRandomizer.html},
  note = {Accessed: 2024-11-13}
}

@InProceedings{10.1007/978-3-642-15549-9_55,
author="Fergus, Rob
and Bernal, Hector
and Weiss, Yair
and Torralba, Antonio",
editor="Daniilidis, Kostas
and Maragos, Petros
and Paragios, Nikos",
title="Semantic Label Sharing for Learning with Many Categories",
booktitle="Computer Vision -- ECCV 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="762--775",
abstract="In an object recognition scenario with tens of thousands of categories, even a small number of labels per category leads to a very large number of total labels required. We propose a simple method of label sharing between semantically similar categories. We leverage the WordNet hierarchy to define semantic distance between any two categories and use this semantic distance to share labels. Our approach can be used with any classifier. Experimental results on a range of datasets, upto 80 million images and 75,000 categories in size, show that despite the simplicity of the approach, it leads to significant improvements in performance.",
isbn="978-3-642-15549-9"
}

@misc{wolfram_spherical_coordinates,
  title = {Spherical Coordinates},
  author = {Weisstein, Eric W.},
  year = {2024},
  url = {https://mathworld.wolfram.com/SphericalCoordinates.html}
}
@misc{unity_quaternion_lookrotation,
  title = {Quaternion.LookRotation},
  author = {Unity Technologies},
  year = {2024},
  url = {https://docs.unity3d.com/ScriptReference/Quaternion.LookRotation.html},
  note = {Accessed: 2024-11-18}
}
@misc{cgtrader,
  title = {CGTrader - 3D Models for Professionals},
    author = {{CGTrader}},
  howpublished = {\url{https://www.cgtrader.com/}},
  note = {Accessed: 2024-11-19}
}
@misc{sketchfab,
  author = {{Sketchfab}},
  title = {Sketchfab - The best 3D viewer on the web},
  howpublished = {\url{https://sketchfab.com/about}},
  note = {Accessed: 2024-11-19}
}

@misc{dnv_wiki,
  author = {{DNV}},
  title = {Azure DevOps Community for ReVolt.},
  howpublished = {Internal resource},
  note = {Accessed: 2024-11-19. Restricted}
}


@Article{jimaging8110310,
AUTHOR = {Man, Keith and Chahl, Javaan},
TITLE = {A Review of Synthetic Image Data and Its Use in Computer Vision},
JOURNAL = {Journal of Imaging},
VOLUME = {8},
YEAR = {2022},
NUMBER = {11},
ARTICLE-NUMBER = {310},
URL = {https://www.mdpi.com/2313-433X/8/11/310},
PubMedID = {36422059},
ISSN = {2313-433X},
ABSTRACT = {Development of computer vision algorithms using convolutional neural networks and deep learning has necessitated ever greater amounts of annotated and labelled data to produce high performance models. Large, public data sets have been instrumental in pushing forward computer vision by providing the data necessary for training. However, many computer vision applications cannot rely on general image data provided in the available public datasets to train models, instead requiring labelled image data that is not readily available in the public domain on a large scale. At the same time, acquiring such data from the real world can be difficult, costly to obtain, and manual labour intensive to label in large quantities. Because of this, synthetic image data has been pushed to the forefront as a potentially faster and cheaper alternative to collecting and annotating real data. This review provides general overview of types of synthetic image data, as categorised by synthesised output, common methods of synthesising different types of image data, existing applications and logical extensions, performance of synthetic image data in different applications and the associated difficulties in assessing data performance, and areas for further research.},
DOI = {10.3390/jimaging8110310}
}



@article{10.1145/3042064,
author = {Ioannidou, Anastasia and Chatzilari, Elisavet and Nikolopoulos, Spiros and Kompatsiaris, Ioannis},
title = {Deep Learning Advances in Computer Vision with 3D Data: A Survey},
year = {2017},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3042064},
doi = {10.1145/3042064},
abstract = {Deep learning has recently gained popularity achieving state-of-the-art performance in tasks involving text, sound, or image processing. Due to its outstanding performance, there have been efforts to apply it in more challenging scenarios, for example, 3D data processing. This article surveys methods applying deep learning on 3D data and provides a classification based on how they exploit them. From the results of the examined works, we conclude that systems employing 2D views of 3D data typically surpass voxel-based (3D) deep models, which however, can perform better with more layers and severe data augmentation. Therefore, larger-scale datasets and increased resolutions are required.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {20},
numpages = {38},
keywords = {3D data, 3D object recognition, 3D object retrieval, 3D segmentation, convolutional neural networks, deep learning}
}

@book{nikolenko2021synthetic,
  title={Synthetic data for deep learning},
  author={Nikolenko, Sergey I},
  volume={174},
  year={2021},
  publisher={Springer}
}
@misc{rajpura2017objectdetectionusingdeep,
      title={Object Detection Using Deep CNNs Trained on Synthetic Images}, 
      author={Param S. Rajpura and Hristo Bojinov and Ravi S. Hegde},
      year={2017},
      eprint={1706.06782},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1706.06782}, 
}

@article{Ying_2019,
doi = {10.1088/1742-6596/1168/2/022022},
url = {https://dx.doi.org/10.1088/1742-6596/1168/2/022022},
year = {2019},
month = {feb},
publisher = {IOP Publishing},
volume = {1168},
number = {2},
pages = {022022},
author = {Xue Ying},
title = {An Overview of Overfitting and its Solutions},
journal = {Journal of Physics: Conference Series},
abstract = {Overfitting is a fundamental issue in supervised machine learning which prevents us from perfectly generalizing the models to well fit observed data on training data, as well as unseen data on testing set. Because of the presence of noise, the limited size of training set, and the complexity of classifiers, overfitting happens. This paper is going to talk about overfitting from the perspectives of causes and solutions. To reduce the effects of overfitting, various strategies are proposed to address to these causes: 1) “early-stopping” strategy is introduced to prevent overfitting by stopping training before the performance stops optimize; 2) “network-reduction” strategy is used to exclude the noises in training set; 3) “data-expansion” strategy is proposed for complicated models to fine-tune the hyper-parameters sets with a great amount of data; and 4) “regularization” strategy is proposed to guarantee models performance to a great extent while dealing with real world issues by feature-selection, and by distinguishing more useful and less useful features.}
}

@article{Labelling,
author = {Christoph Sager, Christian Janiesch and Patrick Zschech},
title = {A survey of image labelling for computer vision applications},
journal = {Journal of Business Analytics},
volume = {4},
number = {2},
pages = {91--110},
year = {2021},
publisher = {Taylor \& Francis},
doi = {10.1080/2573234X.2021.1908861},


URL = { 
    
        https://doi.org/10.1080/2573234X.2021.1908861
    
    

},
eprint = { 
    
        https://doi.org/10.1080/2573234X.2021.1908861
    
    

}

}

@Article{labelingMethods,
AUTHOR = {Mohammed, Sarfaraz Ahmed and Ralescu, Anca L.},
TITLE = {Insights into Image Understanding: Segmentation Methods for Object Recognition and Scene Classification},
JOURNAL = {Algorithms},
VOLUME = {17},
YEAR = {2024},
NUMBER = {5},
ARTICLE-NUMBER = {189},
URL = {https://www.mdpi.com/1999-4893/17/5/189},
ISSN = {1999-4893},
ABSTRACT = {Image understanding plays a pivotal role in various computer vision tasks, such as extraction of essential features from images, object detection, and segmentation. At a higher level of granularity, both semantic and instance segmentation are necessary for fully grasping a scene. In recent times, the concept of panoptic segmentation has emerged as a field of study that unifies semantic and instance segmentation. This article sheds light on the pivotal role of panoptic segmentation as a visualization tool for understanding scene components, including object detection, categorization, and precise localization of scene elements. Advancements in achieving panoptic segmentation and suggested improvements to the predicted outputs through a top-down approach are discussed. Furthermore, datasets relevant to both scene recognition and panoptic segmentation are explored to facilitate a comparative analysis. Finally, the article outlines certain promising directions in image recognition and analysis by underlining the ongoing evolution in image understanding methodologies.},
DOI = {10.3390/a17050189}
}



@article{waterrendering,
  title={Using vertex texture displacement for realistic water rendering},
  author={Kryachko, Yuri},
  journal={GPU gems},
  volume={2},
  pages={283--294},
  year={2005}
}

@article{gan,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative adversarial networks},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3422622},
doi = {10.1145/3422622},
abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
journal = {Commun. ACM},
month = oct,
pages = {139–144},
numpages = {6}
}

@misc{hallucination,
      title={Generative AI for Synthetic Data Generation: Methods, Challenges and the Future}, 
      author={Xu Guo and Yiqiang Chen},
      year={2024},
      eprint={2403.04190},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.04190}, 
}